<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/en/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/en/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/en/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/en/images/logo.svg" color="#222">

<link rel="stylesheet" href="/en/css/main.css">


<link rel="stylesheet" href="/en/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zhouyifan.net","root":"/en/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="在使用预训练 Stable Diffusion (SD) 生成图像时，如果将其 U-Net 的自注意力层在某去噪时刻的输入 K, V 替换成另一幅参考图像的，则输出图像会和参考图像更加相似。许多无需训练的 SD 编辑科研工作都运用了此性质。尤其对于是对于视频编辑任务，如果在生成某一帧时将注意力输入替换成之前帧的，则输出视频会更加连贯。在这篇文章中，我们将快速学习 SD 自注意力替换技术的原理，并在">
<meta property="og:type" content="article">
<meta property="og:title" content="Stable Diffusion 中的自注意力替换技术与 Diffusers 实现">
<meta property="og:url" content="https://zhouyifan.net/en/2024/01/27/20240123-SD-Attn/index.html">
<meta property="og:site_name" content="周弈帆的博客">
<meta property="og:description" content="在使用预训练 Stable Diffusion (SD) 生成图像时，如果将其 U-Net 的自注意力层在某去噪时刻的输入 K, V 替换成另一幅参考图像的，则输出图像会和参考图像更加相似。许多无需训练的 SD 编辑科研工作都运用了此性质。尤其对于是对于视频编辑任务，如果在生成某一帧时将注意力输入替换成之前帧的，则输出视频会更加连贯。在这篇文章中，我们将快速学习 SD 自注意力替换技术的原理，并在">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zhouyifan.net/2024/01/27/20240123-SD-Attn/1.png">
<meta property="og:image" content="https://zhouyifan.net/2024/01/27/20240123-SD-Attn/2.png">
<meta property="og:image" content="https://zhouyifan.net/2024/01/27/20240123-SD-Attn/3.png">
<meta property="og:image" content="https://zhouyifan.net/2024/01/27/20240123-SD-Attn/4.png">
<meta property="og:image" content="https://zhouyifan.net/2024/01/27/20240123-SD-Attn/output.gif">
<meta property="article:published_time" content="2024-01-27T08:48:55.000Z">
<meta property="article:modified_time" content="2024-01-27T08:48:55.984Z">
<meta property="article:author" content="Zhou Yifan">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="编程">
<meta property="article:tag" content="PyTorch">
<meta property="article:tag" content="扩散模型">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zhouyifan.net/2024/01/27/20240123-SD-Attn/1.png">

<link rel="canonical" href="https://zhouyifan.net/en/2024/01/27/20240123-SD-Attn/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Stable Diffusion 中的自注意力替换技术与 Diffusers 实现 | 周弈帆的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/en/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">周弈帆的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/en/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/en/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/en/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/en/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/en/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-switch_lang">

    <a href="https://zhouyifan.net" rel="section"><i class="fa fa-language fa-fw"></i>简体中文</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhouyifan.net/en/2024/01/27/20240123-SD-Attn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/en/images/avatar.gif">
      <meta itemprop="name" content="Zhou Yifan">
      <meta itemprop="description" content="Designer, artist, philosopher, researcher.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="周弈帆的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Stable Diffusion 中的自注意力替换技术与 Diffusers 实现
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-01-27 16:48:55" itemprop="dateCreated datePublished" datetime="2024-01-27T16:48:55+08:00">2024-01-27</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/en/categories/%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">学习</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/en/categories/%E5%AD%A6%E4%B9%A0/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/" itemprop="url" rel="index"><span itemprop="name">知识整理</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>在使用预训练 Stable Diffusion (SD) 生成图像时，如果将其 U-Net 的自注意力层在某去噪时刻的输入 K, V 替换成另一幅参考图像的，则输出图像会和参考图像更加相似。许多无需训练的 SD 编辑科研工作都运用了此性质。尤其对于是对于视频编辑任务，如果在生成某一帧时将注意力输入替换成之前帧的，则输出视频会更加连贯。在这篇文章中，我们将快速学习 SD 自注意力替换技术的原理，并在 Diffusers 里实现一个基于此技术的视频编辑流水线。</p>
<h2 id="注意力计算"><a href="#注意力计算" class="headerlink" title="注意力计算"></a>注意力计算</h2><p>我们先来回顾一下 Transformer 论文中提出的注意力机制。所有注意力机制都基于一种叫做放缩点乘注意力（Scaled Dot-Product Attention）的运算：</p>
<script type="math/tex; mode=display">
Attention(Q, K, V)=softmax(\frac{QK^T}{\sqrt{d_k}})V</script><p>其中，$Q \in \mathbb{R}^{a \times d_k}, K \in \mathbb{R}^{b \times d_k}, V \in \mathbb{R}^{b \times d_v}$。注意力计算可以理解成先算 $a$ 个长度为 $d_k$ 的向量对 $b$ 个长度为 $d_k$ 的向量的相似度，再以此相似度为权重算 $a$ 个向量对 $b$ 个长度为 $d_v$ 的向量的加权和。</p>
<p>注意力计算是没有可学习参数的。为了加入参数，Transformer 设计了如下所示的注意力层，其中 $W^Q, W^K, W^V, W^O$ 都是参数。</p>
<script type="math/tex; mode=display">
AttnLayer(Q, K, V) = Attention(QW^Q, KW^K, VW^V)W^O</script><p>一般在使用注意力层时，会让$K=V$。这种注意力叫做交叉注意力。交叉注意力可以理解成数据 $A$ 想从数据 $B$ 里提取信息，提取的根据是 $A$ 里每个向量和 $B$ 里每个向量的相似度。 </p>
<script type="math/tex; mode=display">
CrossAttnLayer(A, B) = Attention(AW^Q, BW^K, BW^V)W^O</script><p>交叉注意力的特例是自注意力，此时 $Q=K=V$ 。这表示数据里的向量两两之间交换了一次信息。</p>
<script type="math/tex; mode=display">
SelfAttnLayer(A) = Attention(AW^Q, AW^K, AW^V)W^O</script><h2 id="SD-中的自注意力替换"><a href="#SD-中的自注意力替换" class="headerlink" title="SD 中的自注意力替换"></a>SD 中的自注意力替换</h2><p>SD 的 U-Net 既用到了自注意力，也用到了交叉注意力。自注意力用于图像特征自己内部信息聚合。交叉注意力用于让生成图像对齐文本，其 Q 来自图像特征，K, V 来自文本编码。</p>
<p><img src="/2024/01/27/20240123-SD-Attn/1.png" alt></p>
<p>由于自注意力其实可以看成一种特殊的交叉注意力，我们可以把自注意力的 K, V 替换成来自另一幅参考图像的特征。这样，扩散模型的生成图片会既和原本要生成的图像相似，又和参考图像相似。当然，用来替换的特征必须和原来的特征「格式一致」，不然就生成不了有意义的结果了。</p>
<p><img src="/2024/01/27/20240123-SD-Attn/2.png" alt></p>
<p>什么叫「格式一致」呢？我们知道，扩散模型在采样时有很多步，U-Net 中又有许多自注意力层。每一步时的每一个自注意力层的输入都有自己的「格式」。也就是说，如果你要把某时刻某自注意力层的 K, V 替换，就得先生成参考图像，用生成参考图像过程中此时刻此自注意力层的输入替换，而不能用其他时刻或者其他自注意力层的。</p>
<p><img src="/2024/01/27/20240123-SD-Attn/3.png" alt></p>
<p><img src="/2024/01/27/20240123-SD-Attn/4.png" alt></p>
<p>一般这种编辑技术只会用在自注意力层而不是交叉注意力层上，这是因为 SD 中的交叉注意力是用来关联图像与文字的，另一幅图像的信息无法输入。当然，除了 SD，只要是用到了自注意力模块的扩散模型，都能用此方法编辑，只不过大部分工作都是基于 SD 开发的。</p>
<h2 id="自注意力替换的应用"><a href="#自注意力替换的应用" class="headerlink" title="自注意力替换的应用"></a>自注意力替换的应用</h2><p>自注意力替换最常见的应用是提升 SD 视频编辑的连续性。在此任务中，一般会先正常编辑第一帧，再将后续帧的自注意力的 K, V 替换成第一帧的。这种技术在文献中一般被称为帧间注意力（cross-frame attention）。较早提出此论文的工作是 Text2Video-Zero。</p>
<p>自注意力替换也可以用于提升单幅图像编辑的保真度。一个例子是拖拽单幅图像的 DragonDiffusion。此应用可以拓展到图像插值上，比如 DiffMorpher 在图像插值时对两幅参考图像的自注意力输入等比例插值，再替换掉对应插值图像的自注意力的 K, V。</p>
<h2 id="在-Diffusers-里实现自注意力替换"><a href="#在-Diffusers-里实现自注意力替换" class="headerlink" title="在 Diffusers 里实现自注意力替换"></a>在 Diffusers 里实现自注意力替换</h2><p>Diffusers 的 U-Net 专门提供了用于修改注意力计算的 <code>AttentionProcessor</code> 类。借助相关接口，我们可以方便地修改注意力的计算方法。在这个示例项目中，我们来用 Diffusers 实现一个参考第一帧和上一帧的注意力输入的 SD 视频编辑流水线。相比逐帧生成编辑图片，该流水线的结果会更加平滑一点。项目网址：<a target="_blank" rel="noopener" href="https://github.com/SingleZombie/DiffusersExample/tree/main/ReplaceAttn">https://github.com/SingleZombie/DiffusersExample/tree/main/ReplaceAttn</a> 。</p>
<h3 id="AttentionProcessor"><a href="#AttentionProcessor" class="headerlink" title="AttentionProcessor"></a><code>AttentionProcessor</code></h3><p>在 Diffusers 中，U-Net 的每一个注意力模块都有一个 <code>AttentionProcessor</code> 类的实例。<code>AttentionProcessor</code> 类的 <code>__call__</code> 方法描述了注意力计算的过程。如果我们想修改某些注意力模块的计算，就需要自己定义一个注意力处理类，其 <code>__call__</code> 方法的参数需与 <code>AttentionProcessor</code> 的兼容。之后，我们再调用相关接口把原来的处理类换成我们自己写的处理类。下面我们将先看一下 <code>AttentionProcessor</code> 类的实现细节，再实现我们自己的<br>注意力处理类。</p>
<p><code>AttentionProcessor</code> 类在 <code>diffusers/models/attention_processor.py</code> 文件里。它只有一个 <code>__call__</code> 方法，其主要内容如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AttnProcessor</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        attn: Attention,</span></span></span><br><span class="line"><span class="params"><span class="function">        hidden_states: torch.FloatTensor,</span></span></span><br><span class="line"><span class="params"><span class="function">        encoder_hidden_states: <span class="type">Optional</span>[torch.FloatTensor] = <span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        attention_mask: <span class="type">Optional</span>[torch.FloatTensor] = <span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        temb: <span class="type">Optional</span>[torch.FloatTensor] = <span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        scale: <span class="built_in">float</span> = <span class="number">1.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>) -&gt; torch.Tensor:</span></span><br><span class="line">        residual = hidden_states</span><br><span class="line">        query = attn.to_q(hidden_states, *args)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> encoder_hidden_states <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            encoder_hidden_states = hidden_states</span><br><span class="line"></span><br><span class="line">        key = attn.to_k(encoder_hidden_states, *args)</span><br><span class="line">        value = attn.to_v(encoder_hidden_states, *args)</span><br><span class="line"></span><br><span class="line">        query = attn.head_to_batch_dim(query)</span><br><span class="line">        key = attn.head_to_batch_dim(key)</span><br><span class="line">        value = attn.head_to_batch_dim(value)</span><br><span class="line"></span><br><span class="line">        attention_probs = attn.get_attention_scores(query, key, attention_mask)</span><br><span class="line">        hidden_states = torch.bmm(attention_probs, value)</span><br><span class="line">        hidden_states = attn.batch_to_head_dim(hidden_states)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># linear proj</span></span><br><span class="line">        hidden_states = attn.to_out[<span class="number">0</span>](hidden_states, *args)</span><br><span class="line">        <span class="comment"># dropout</span></span><br><span class="line">        hidden_states = attn.to_out[<span class="number">1</span>](hidden_states)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> attn.residual_connection:</span><br><span class="line">            hidden_states = hidden_states + residual</span><br><span class="line"></span><br><span class="line">        hidden_states = hidden_states / attn.rescale_output_factor</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> hidden_states</span><br></pre></td></tr></table></figure>
<p>方法参数中，<code>hidden_states</code> 是 Q， <code>encoder_hidden_states</code> 是 K, V。如果 K, V 没有传入（为 <code>None</code>），则 K, V 会被赋值成 Q。该方法的实现细节和 Tranformer 中的注意力层完全一样，此处就不多加解释了。一般替换注意力的输入时，我们不用改这个方法的实现，只会在需要的时候调用这个方法。</p>
<script type="math/tex; mode=display">
AttnLayer(Q, K, V) = Attention(QW^Q, KW^K, VW^V)W^O</script><p><code>attention_processor.py</code> 文件中还有一个功能类似的类 <code>AttnProcessor2_0</code>，它和 <code>AttentionProcessor</code> 的区别在于它调用了 PyTorch 2.0 起启用的算子 <code>F.scaled_dot_product_attention</code> 代替手动实现的注意力计算。这个算子更加高效，如果你确定 PyTorch 版本至少为 2.0，就可以用 <code>AttnProcessor2_0</code> 代替 <code>AttentionProcessor</code>。</p>
<p>看完了 <code>AttentionProcessor</code> 类后，我们来看该怎么在 U-Net 里将原注意力处理类替换成我们自己写的。U-Net 类的 <code>attn_processors</code> 属性会返回一个词典，它的 key 是每个处理类所在位置，比如 <code>down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor</code>，它的 value 是每个处理类的实例。为了替换处理类，我们需要构建一个格式一样的词典<code>attn_processor_dict</code>，再调用 <code>unet.set_attn_processor(attn_processor_dict)</code> ，取代原来的 <code>attn_processors</code>。假如我们自己实现了处理类 <code>MyAttnProcessor</code>，我们可以编写下面的代码来实现替换：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">attn_processor_dict = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> unet.attn_processors.keys():</span><br><span class="line">    <span class="keyword">if</span> we_want_to_modify(k):</span><br><span class="line">        attn_processor_dict[k] = MyAttnProcessor()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        attn_processor_dict[k] = AttnProcessor()</span><br><span class="line"></span><br><span class="line">unet.set_attn_processor(attn_processor_dict)</span><br></pre></td></tr></table></figure>
<h3 id="实现帧间注意力处理类"><a href="#实现帧间注意力处理类" class="headerlink" title="实现帧间注意力处理类"></a>实现帧间注意力处理类</h3><p>熟悉了 <code>AttentionProcessor</code> 类的相关内容，我们来编写自己的帧间注意力处理类。在处理第一帧时，该类的行为不变。对于之后的每一帧，该类的 K, V 输入会被替换成视频第一帧和上一帧的输入在序列长度维度上的拼接结果，即：</p>
<script type="math/tex; mode=display">
CrossFrameAttn(A, A_1, A_{prev}) = CrossAttnLayer(A, [A_1, A_{prev}])</script><blockquote>
<p>你是否会感到疑惑：为什么 K, V 的序列长度可以修改？别忘了，在注意力计算中，Q, K, V 的形状分别是：$Q \in \mathbb{R}^{a \times d_k}, K \in \mathbb{R}^{b \times d_k}, V \in \mathbb{R}^{b \times d_v}$。注意力计算只要求 K，V 的序列长度 $b$ 相同，并没有要求 Q, K 的序列长度相同。</p>
</blockquote>
<p>现在，注意力计算不再是一个没有状态的计算，它的运算结果取决于第一帧和上一帧的输入。因此，我们在注意力处理类中需要额外维护这两个变量。我们可以按照如下代码编写类的构造函数。除了处理继承外，我们还需要创建两个数据词典来存储不同时间戳下第一帧和上一帧的注意力输入。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CrossFrameAttnProcessor</span>(<span class="params">AttnProcessor</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.first_maps = &#123;&#125;</span><br><span class="line">        self.prev_maps = &#123;&#125;</span><br></pre></td></tr></table></figure>
<p>在运行方法中，我们根据 <code>encoder_hidden_states</code> 是否为空来判断该注意力是自注意力还是交叉注意力。我们仅修改自注意力。当该注意力为自注意力时，假设我们知道了当前时刻 <code>t</code>，我们就可以根据 <code>t</code> 获取当前时刻第一帧和前一帧的输入，并将它们拼接起来得到 <code>cross_map</code>。以此 <code>cross_map</code> 为当前注意力的 K, V，我们就实现了帧间注意力。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, attn: Attention, hidden_states, encoder_hidden_states=<span class="literal">None</span>, **kwargs</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> encoder_hidden_states <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># Is self attention</span></span><br><span class="line">        cross_map = torch.cat(</span><br><span class="line">            (self.first_maps[t], self.prev_maps[t]), dim=<span class="number">1</span>)</span><br><span class="line">        res = <span class="built_in">super</span>().__call__(attn, hidden_states, cross_map, **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># Is cross attention</span></span><br><span class="line">        res = <span class="built_in">super</span>().__call__(attn, hidden_states, encoder_hidden_states, **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<blockquote>
<p>由于 Diffusers 经常修改函数接口，在调用普通的注意力计算接口时，最好原封不动地按照 <code>super().__call__(..., **kwargs)</code> 写，不然这份代码就不能兼容后续版本的 Diffusers。</p>
</blockquote>
<p>上述代码只描述了后续帧的行为。如前所述，我们的注意力计算有两种行为：对于第一帧，我们不修改注意力的计算过程，只缓存其输入；对于之后每一帧，我们替换注意力的输入，同时维护当前「上一帧」的输入。既然注意力在不同情况下有不同行为，我们就应该用一个变量来记录当前状态，让 <code>__call__</code> 能根据此变量决定当前的行为。相关的伪代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, attn: Attention, hidden_states, encoder_hidden_states=<span class="literal">None</span>, **kwargs</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> encoder_hidden_states <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># Is self attention</span></span><br><span class="line">        <span class="keyword">if</span> self.state == FIRST_FRAME:</span><br><span class="line">            res = <span class="built_in">super</span>().__call__(attn, hidden_states, cross_map, **kwargs)</span><br><span class="line">            <span class="comment"># update maps</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            cross_map = torch.cat(</span><br><span class="line">                (self.first_maps[t], self.prev_maps[t]), dim=<span class="number">1</span>)</span><br><span class="line">            res = <span class="built_in">super</span>().__call__(attn, hidden_states, cross_map, **kwargs)</span><br><span class="line">            <span class="comment"># update maps</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># Is cross attention</span></span><br><span class="line">        res = <span class="built_in">super</span>().__call__(attn, hidden_states, encoder_hidden_states, **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p>在伪代码中，<code>self.state</code> 表示当前注意力的状态，它的值表明注意力计算是在处理第一帧还是后续帧。在视频编辑流水线中，我们应按照下面的伪代码，先编辑第一帧，再修改注意力状态后编辑后续帧。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">edit(frames[<span class="number">0</span>])</span><br><span class="line">set_attn_state(SUBSEQUENT_FRAMES)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(frames)):</span><br><span class="line">    edit(frames[i])</span><br></pre></td></tr></table></figure>
<p>现在，有一个问题：我们该怎么修改怎么每一个注意力模块的处理器的状态呢？显然，最直接的方式是想办法访问每一个注意力模块的处理器，再直接修改对象的属性。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">modules = unet.get_attn_moduels</span><br><span class="line"><span class="keyword">for</span> module <span class="keyword">in</span> modules:</span><br><span class="line">    <span class="keyword">if</span> we_want_to_modify(module):</span><br><span class="line">        module.processor.state = ...</span><br></pre></td></tr></table></figure>
<p>但是，每次都去遍历所有模块会让代码更加凌乱。同时，这样写也会带来代码维护上的问题：我们每次遍历注意力模块时，都可能要判断该注意力模块是否应该修改。而在用前面讲过的处理类替换方法 <code>unet.set_attn_processor</code> 时，我们也得判断一遍。同一段逻辑重复写在两个地方，非常不利于代码更新。</p>
<p>一种更优雅的实现方式是：我们定义一个状态管理类，所有注意力处理器都从同一个全局状态管理类对象里获取当前的状态信息。想修改每一个处理器的状态，不需要遍历所有对象，只需要改一次全局状态管理类对象就行了。</p>
<p>按照这种实现方式，我们先编写一个状态类。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AttnState</span>:</span></span><br><span class="line">    STORE = <span class="number">0</span></span><br><span class="line">    LOAD = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.reset()</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">state</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.__state</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reset</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.__state = AttnState.STORE</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">to_load</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.__state = AttnState.LOAD</span><br></pre></td></tr></table></figure>
<p>在注意力处理类中，我们在初始化时保存状态类对象的引用，在运行时根据状态类对象获取当前状态。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CrossFrameAttnProcessor</span>(<span class="params">AttnProcessor</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, attn_state: AttnState</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.attn_state = attn_state</span><br><span class="line">        self.first_maps = &#123;&#125;</span><br><span class="line">        self.prev_maps = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, attn: Attention, hidden_states, encoder_hidden_states=<span class="literal">None</span>, **kwargs</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> encoder_hidden_states <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># Is self attention</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self.attn_state.state == AttnState.STORE:</span><br><span class="line">                res = <span class="built_in">super</span>().__call__(attn, hidden_states, encoder_hidden_states, **kwargs)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                cross_map = torch.cat(</span><br><span class="line">                    (self.first_maps[t], self.prev_maps[t]), dim=<span class="number">1</span>)</span><br><span class="line">                res = <span class="built_in">super</span>().__call__(attn, hidden_states, cross_map, **kwargs)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># Is cross attention</span></span><br><span class="line">            res = <span class="built_in">super</span>().__call__(attn, hidden_states, encoder_hidden_states, **kwargs)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p>到目前为止，假设已经维护好了之前的输入，我们的注意力处理类能执行两种不同的行为了。现在，我们来实现之前输入的维护。使用之前的注意力输入时，我们其实需要知道当前的时刻 <code>t</code>。当前的时刻也算是另一个状态，最好是也在状态管理类里维护。但为了简化我们的代码，我们可以偷懒让每个处理类自己维护当前时刻。具体做法是：如果知道了去噪迭代的总时刻数，我们就可以令当前时刻从0开始不断自增，直到最大时刻时，再重置为0。加入了时刻处理及之前输入维护的完整代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AttnState</span>:</span></span><br><span class="line">    STORE = <span class="number">0</span></span><br><span class="line">    LOAD = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.reset()</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">state</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.__state</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">timestep</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.__timestep</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_timestep</span>(<span class="params">self, t</span>):</span></span><br><span class="line">        self.__timestep = t</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reset</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.__state = AttnState.STORE</span><br><span class="line">        self.__timestep = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">to_load</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.__state = AttnState.LOAD</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CrossFrameAttnProcessor</span>(<span class="params">AttnProcessor</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, attn_state: AttnState</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.attn_state = attn_state</span><br><span class="line">        self.cur_timestep = <span class="number">0</span></span><br><span class="line">        self.first_maps = &#123;&#125;</span><br><span class="line">        self.prev_maps = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, attn: Attention, hidden_states, encoder_hidden_states=<span class="literal">None</span>, **kwargs</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> encoder_hidden_states <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># Is self attention</span></span><br><span class="line"></span><br><span class="line">            tot_timestep = self.attn_state.timestep</span><br><span class="line">            <span class="keyword">if</span> self.attn_state.state == AttnState.STORE:</span><br><span class="line">                self.first_maps[self.cur_timestep] = hidden_states.detach()</span><br><span class="line">                self.prev_maps[self.cur_timestep] = hidden_states.detach()</span><br><span class="line">                res = <span class="built_in">super</span>().__call__(attn, hidden_states, encoder_hidden_states, **kwargs)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                tmp = hidden_states.detach()</span><br><span class="line">                cross_map = torch.cat(</span><br><span class="line">                    (self.first_maps[self.cur_timestep], self.prev_maps[self.cur_timestep]), dim=<span class="number">1</span>)</span><br><span class="line">                res = <span class="built_in">super</span>().__call__(attn, hidden_states, cross_map, **kwargs)</span><br><span class="line">                self.prev_maps[self.cur_timestep] = tmp</span><br><span class="line"></span><br><span class="line">            self.cur_timestep += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> self.cur_timestep == tot_timestep:</span><br><span class="line">                self.cur_timestep = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># Is cross attention</span></span><br><span class="line">            res = <span class="built_in">super</span>().__call__(attn, hidden_states, encoder_hidden_states, **kwargs)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p>代码中，<code>tot_timestep</code> 为总时刻数，<code>cur_timestep</code> 为当前时刻。每运算一次，<code>cur_timestep</code> 加一，直至总时刻时再归零。在处理第一帧时，我们把当前时刻的输入同时存入第一帧缓存 <code>first_maps</code> 和上一帧缓存 <code>prev_maps</code> 中。对于后续帧，我们先做替换过输入的注意力计算，再更新上一帧缓存 <code>prev_maps</code>。</p>
<h3 id="视频编辑流水线"><a href="#视频编辑流水线" class="headerlink" title="视频编辑流水线"></a>视频编辑流水线</h3><p>准备好了我们自己写的帧间注意力处理类后，我们来编写一个简单的 Diffusers 视频处理流水线。该流水线基于 ControlNet 与图生图流水线，其主要代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VideoEditingPipeline</span>(<span class="params">StableDiffusionControlNetImg2ImgPipeline</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        ...</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(...)</span><br><span class="line">        self.attn_state = AttnState()</span><br><span class="line">        attn_processor_dict = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> unet.attn_processors.keys():</span><br><span class="line">            <span class="keyword">if</span> k.startswith(<span class="string">&quot;up&quot;</span>):</span><br><span class="line">                attn_processor_dict[k] = CrossFrameAttnProcessor(</span><br><span class="line">                    self.attn_state)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                attn_processor_dict[k] = AttnProcessor()</span><br><span class="line"></span><br><span class="line">        self.unet.set_attn_processor(attn_processor_dict)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, *args, images=<span class="literal">None</span>, control_images=<span class="literal">None</span>,  **kwargs</span>):</span></span><br><span class="line">        self.attn_state.reset()</span><br><span class="line">        self.attn_state.set_timestep(</span><br><span class="line">            <span class="built_in">int</span>(kwargs[<span class="string">&#x27;num_inference_steps&#x27;</span>] * kwargs[<span class="string">&#x27;strength&#x27;</span>]))</span><br><span class="line">        outputs = [<span class="built_in">super</span>().__call__(</span><br><span class="line">            *args, **kwargs, image=images[<span class="number">0</span>], control_image=control_images[<span class="number">0</span>]).images[<span class="number">0</span>]]</span><br><span class="line">        self.attn_state.to_load()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(images)):</span><br><span class="line">            image = images[i]</span><br><span class="line">            control_image = control_images[i]</span><br><span class="line">            outputs.append(<span class="built_in">super</span>().__call__(</span><br><span class="line">                *args, **kwargs, image=image, control_image=control_image).images[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure>
<p>在构造函数中，我们创建了一个全局注意力状态对象 <code>attn_state</code>。它的引用会传给每一个帧间注意力处理对象。一般修改自注意力模块时，只会修改 U-Net 上采样部分的，而不会动下采样部分和中间部分的。因此，在过滤注意力模块时，我们的判断条件是 <code>k.startswith(&quot;up&quot;)</code>。把新的注意力处理器词典填完后，用 <code>unet.set_attn_processor</code> 更新所有的处理类对象。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">self.attn_state = AttnState()</span><br><span class="line">attn_processor_dict = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> unet.attn_processors.keys():</span><br><span class="line">    <span class="keyword">if</span> k.startswith(<span class="string">&quot;up&quot;</span>):</span><br><span class="line">        attn_processor_dict[k] = CrossFrameAttnProcessor(</span><br><span class="line">            self.attn_state)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        attn_processor_dict[k] = AttnProcessor()</span><br><span class="line"></span><br><span class="line">self.unet.set_attn_processor(attn_processor_dict)</span><br></pre></td></tr></table></figure>
<p>在 <code>__call__</code> 方法中，我们要基于原图像编辑流水线 <code>super().__call__()</code>，实现我们的视频编辑流水线。在这个过程中，我们的主要任务是维护好注意力管理对象中的状态。一开始，我们要把管理类重置，根据参数设置最大去噪时刻数。经重置后，注意力处理器的状态默认为 <code>STORE</code>，即会保存第一帧的输入。处理完第一帧后，我们运行 <code>attn_state.to_load()</code> 改变注意力处理器的状态，让它们每次做注意力运算时先读第一帧和上一帧的输入，再维护上一帧输入的缓存。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, *args, images=<span class="literal">None</span>, control_images=<span class="literal">None</span>,  **kwargs</span>):</span></span><br><span class="line">    self.attn_state.reset()</span><br><span class="line">    self.attn_state.set_timestep(</span><br><span class="line">        <span class="built_in">int</span>(kwargs[<span class="string">&#x27;num_inference_steps&#x27;</span>] * kwargs[<span class="string">&#x27;strength&#x27;</span>]))</span><br><span class="line">    outputs = [<span class="built_in">super</span>().__call__(</span><br><span class="line">        *args, **kwargs, image=images[<span class="number">0</span>], control_image=control_images[<span class="number">0</span>]).images[<span class="number">0</span>]]</span><br><span class="line">    self.attn_state.to_load()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(images)):</span><br><span class="line">        image = images[i]</span><br><span class="line">        control_image = control_images[i]</span><br><span class="line">        outputs.append(<span class="built_in">super</span>().__call__(</span><br><span class="line">            *args, **kwargs, image=image, control_image=control_image).images[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure>
<p>运行该流水线的示例脚本在项目根目录下的 <code>replace_attn.py</code> 文件中。示例中使用的视频可以在 <code>https://github.com/williamyang1991/Rerender_A_Video/blob/main/videos/pexels-koolshooters-7322716.mp4</code> 下载，下载后应重命名为 <code>woman.mp4</code>。不使用和使用新注意力处理器的输出结果如下：</p>
<p><img src="/2024/01/27/20240123-SD-Attn/output.gif" alt></p>
<p>可以看出，虽然注意力替换不能解决生成视频的闪烁问题，但帧间的一致性提升了不少。将注意力替换技术和其他技术结合起来的话，我们就能得到一个不错的 SD 视频生成工具。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>扩散模型中的自注意力替换是一种常见的提升图片一致性的技术。该技术的实现方法是将扩散模型 U-Net 中自注意力的 K, V 输入替换成另一幅图片的。在这篇文章中，我们学习了一个较为复杂的基于 Diffusers 开发的自注意力替换示例项目，用于提升 SD 视频生成的一致性。在这个过程中，我们学习了和 <code>AttentionProcessor</code> 相关接口函数的使用，并了解了如何基于全局管理类实现一个代码可维护性强的多行为注意力处理类。如果你能看懂这篇文章的示例，那你在开发 Diffusers 的注意力处理类时基本上不会碰到任何难题。</p>
<p>项目网址：<a target="_blank" rel="noopener" href="https://github.com/SingleZombie/DiffusersExample/tree/main/ReplaceAttn">https://github.com/SingleZombie/DiffusersExample/tree/main/ReplaceAttn</a></p>
<p>如果你想进一步学习 Diffusers 中视频编辑流水线的开发，可以参考我给 Diffusers 写的流水线：<a target="_blank" rel="noopener" href="https://github.com/huggingface/diffusers/tree/main/examples/community#Rerender_A_Video">https://github.com/huggingface/diffusers/tree/main/examples/community#Rerender_A_Video</a></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/en/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a>
              <a href="/en/tags/%E7%BC%96%E7%A8%8B/" rel="tag"># 编程</a>
              <a href="/en/tags/PyTorch/" rel="tag"># PyTorch</a>
              <a href="/en/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/" rel="tag"># 扩散模型</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/en/2024/01/23/20240114-SD-LoRA/" rel="prev" title="LoRA 在 Stable Diffusion 中的三种应用：原理讲解与代码示例">
      <i class="fa fa-chevron-left"></i> LoRA 在 Stable Diffusion 中的三种应用：原理讲解与代码示例
    </a></div>
      <div class="post-nav-item">
    <a href="/en/2024/02/21/20240216-Sora-Comment/" rel="next" title="OpenAI 视频模型 Sora 科研贡献速览">
      OpenAI 视频模型 Sora 科研贡献速览 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B%E8%AE%A1%E7%AE%97"><span class="nav-number">1.</span> <span class="nav-text">注意力计算</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SD-%E4%B8%AD%E7%9A%84%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9B%BF%E6%8D%A2"><span class="nav-number">2.</span> <span class="nav-text">SD 中的自注意力替换</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9B%BF%E6%8D%A2%E7%9A%84%E5%BA%94%E7%94%A8"><span class="nav-number">3.</span> <span class="nav-text">自注意力替换的应用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9C%A8-Diffusers-%E9%87%8C%E5%AE%9E%E7%8E%B0%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9B%BF%E6%8D%A2"><span class="nav-number">4.</span> <span class="nav-text">在 Diffusers 里实现自注意力替换</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#AttentionProcessor"><span class="nav-number">4.1.</span> <span class="nav-text">AttentionProcessor</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E5%B8%A7%E9%97%B4%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%A4%84%E7%90%86%E7%B1%BB"><span class="nav-number">4.2.</span> <span class="nav-text">实现帧间注意力处理类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%86%E9%A2%91%E7%BC%96%E8%BE%91%E6%B5%81%E6%B0%B4%E7%BA%BF"><span class="nav-number">4.3.</span> <span class="nav-text">视频编辑流水线</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">5.</span> <span class="nav-text">总结</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Zhou Yifan</p>
  <div class="site-description" itemprop="description">Designer, artist, philosopher, researcher.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/en/archives/">
        
          <span class="site-state-item-count">140</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/en/categories/">
          
        <span class="site-state-item-count">22</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/en/tags/">
          
        <span class="site-state-item-count">63</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhou Yifan</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/en/lib/anime.min.js"></script>
  <script src="/en/lib/velocity/velocity.min.js"></script>
  <script src="/en/lib/velocity/velocity.ui.min.js"></script>

<script src="/en/js/utils.js"></script>

<script src="/en/js/motion.js"></script>


<script src="/en/js/schemes/muse.js"></script>


<script src="/en/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
