<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zhouyifan.net","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="相比于多数图像生成模型，去噪扩散概率模型（Denoising Diffusion Probabilistic Model, DDPM）的采样速度非常慢。这是因为DDPM在采样时通常要做1000次去噪操作。但如果你玩过基于扩散模型的图像生成应用的话，你会发现，大多数应用只需要20次去噪即可生成图像。这是为什么呢？原来，这些应用都使用了一种更快速的采样方法——去噪扩散隐式模型（Denoising Di">
<meta property="og:type" content="article">
<meta property="og:title" content="DDIM 简明讲解与 PyTorch 实现：加速扩散模型采样的通用方法">
<meta property="og:url" content="https://zhouyifan.net/2023/07/07/20230702-DDIM/index.html">
<meta property="og:site_name" content="周弈帆的博客">
<meta property="og:description" content="相比于多数图像生成模型，去噪扩散概率模型（Denoising Diffusion Probabilistic Model, DDPM）的采样速度非常慢。这是因为DDPM在采样时通常要做1000次去噪操作。但如果你玩过基于扩散模型的图像生成应用的话，你会发现，大多数应用只需要20次去噪即可生成图像。这是为什么呢？原来，这些应用都使用了一种更快速的采样方法——去噪扩散隐式模型（Denoising Di">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zhouyifan.net/2023/07/07/20230702-DDIM/1.jpg">
<meta property="og:image" content="https://zhouyifan.net/2023/07/07/20230702-DDIM/2.jpg">
<meta property="og:image" content="https://zhouyifan.net/2023/07/07/20230702-DDIM/3.jpg">
<meta property="og:image" content="https://zhouyifan.net/2023/07/07/20230702-DDIM/4.jpg">
<meta property="og:image" content="https://zhouyifan.net/2023/07/07/20230702-DDIM/5.jpg">
<meta property="og:image" content="https://zhouyifan.net/2023/07/07/20230702-DDIM/6.jpg">
<meta property="og:image" content="https://zhouyifan.net/2023/07/07/20230702-DDIM/7.jpg">
<meta property="og:image" content="https://zhouyifan.net/2023/07/07/20230702-DDIM/7.jpg">
<meta property="og:image" content="https://zhouyifan.net/2023/07/07/20230702-DDIM/4.jpg">
<meta property="article:published_time" content="2023-07-07T12:57:59.000Z">
<meta property="article:modified_time" content="2023-09-27T16:09:35.016Z">
<meta property="article:author" content="Zhou Yifan">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="扩散模型">
<meta property="article:tag" content="Python">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zhouyifan.net/2023/07/07/20230702-DDIM/1.jpg">

<link rel="canonical" href="https://zhouyifan.net/2023/07/07/20230702-DDIM/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>DDIM 简明讲解与 PyTorch 实现：加速扩散模型采样的通用方法 | 周弈帆的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">周弈帆的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhouyifan.net/2023/07/07/20230702-DDIM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhou Yifan">
      <meta itemprop="description" content="A foresighted strategist with big-picture thinking. 大局观选手。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="周弈帆的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          DDIM 简明讲解与 PyTorch 实现：加速扩散模型采样的通用方法
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-07-07 20:57:59" itemprop="dateCreated datePublished" datetime="2023-07-07T20:57:59+08:00">2023-07-07</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">学习</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/" itemprop="url" rel="index"><span itemprop="name">知识整理</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>相比于多数图像生成模型，去噪扩散概率模型（Denoising Diffusion Probabilistic Model, DDPM）的采样速度非常慢。这是因为DDPM在采样时通常要做1000次去噪操作。但如果你玩过基于扩散模型的图像生成应用的话，你会发现，大多数应用只需要20次去噪即可生成图像。这是为什么呢？原来，这些应用都使用了一种更快速的采样方法——去噪扩散隐式模型（Denoising Diffusion Implicit Model, DDIM）。</p>
<p>基于DDPM，DDIM论文主要提出了两项改进。第一，对于一个已经训练好的DDPM，只需要对采样公式做简单的修改，模型就能在去噪时「跳步骤」，在一步去噪迭代中直接预测若干次去噪后的结果。比如说，假设模型从时刻$T=100$开始去噪，新的模型可以在每步去噪迭代中预测10次去噪操作后的结果，也就是逐步预测时刻$t=90, 80, …, 0$的结果。这样，DDPM的采样速度就被加速了10倍。第二，DDIM论文推广了DDPM的数学模型，从更高的视角定义了DDPM的前向过程（加噪过程）和反向过程（去噪过程）。在这个新数学模型下，我们可以自定义模型的噪声强度，让同一个训练好的DDPM有不同的采样效果。</p>
<p>在这篇文章中，我将言简意赅地介绍DDIM的建模方法，并给出我的DDIM PyTorch实现与实验结果。本文不会深究DDIM的数学推导，对这部分感兴趣的读者可以去阅读我在文末给出的参考资料。</p>
<h2 id="回顾-DDPM"><a href="#回顾-DDPM" class="headerlink" title="回顾 DDPM"></a>回顾 DDPM</h2><p>DDIM是建立在DDPM之上的一篇工作。在正式认识DDIM之前，我们先回顾一下DDPM中的一些关键内容，再从中引出DDIM的改进思想。</p>
<p>DDPM是一个特殊的VAE。它的编码器是$T$步固定的加噪操作，解码器是$T$步可学习的去噪操作。模型的学习目标是让每一步去噪操作尽可能抵消掉对应的加噪操作。</p>
<p><img src="/2023/07/07/20230702-DDIM/1.jpg" alt></p>
<p>DDPM的加噪和去噪操作其实都是在某个正态分布中采样。因此，我们可以用概率$q, p$分别表示加噪和去噪的分布。比如 $q(\mathbf{x}_t|\mathbf{x}_{t-1})$ 就是由第 $t-1$ 时刻的图像到第 $t$ 时刻的图像的加噪声分布， $p(\mathbf{x}_{t-1}|\mathbf{x}_{t})$ 就是由第 $t$ 时刻的图像到第 $t-1$ 时刻的图像的去噪声分布。这样，我们可以说网络的学习目标是让 $p(\mathbf{x}_{t-1} | \mathbf{x}_{t})$ 尽可能与 $q(\mathbf{x}_t | \mathbf{x}_{t-1})$ 和互逆。</p>
<p>但是，「互逆」并不是一个严格的数学表述。更具体地，我们应该让分布$p(\mathbf{x}_{t-1} | \mathbf{x}_{t})$和分布$q(\mathbf{x}_{t-1} | \mathbf{x}_{t})$尽可能相似。$q(\mathbf{x}_{t-1} | \mathbf{x}_{t})$和$p(\mathbf{x}_{t-1} | \mathbf{x}_{t})$的关系就和VAE中原图像与重建图像的关系一样。</p>
<p><img src="/2023/07/07/20230702-DDIM/2.jpg" alt></p>
<p>$q(\mathbf{x}_{t-1} | \mathbf{x}_{t})$是不好求得的，但在给定了输入数据$\mathbf{x}_{0}$时，$q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_{0})$是可以用贝叶斯公式求出来的：</p>
<script type="math/tex; mode=display">
q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0) = q(\mathbf{x}_{t} | \mathbf{x}_{t - 1}, \mathbf{x}_0)\frac{q(\mathbf{x}_{t-1} | \mathbf{x}_0)}{q(\mathbf{x}_{t} | \mathbf{x}_0)}</script><p>我们不必关心具体的求解方法，只需要知道从等式右边的三项$q(\mathbf{x}_{t} | \mathbf{x}_{t - 1}, \mathbf{x}_0)、q(\mathbf{x}_{t-1} | \mathbf{x}_0)、q(\mathbf{x}_{t} | \mathbf{x}_0)$可以推导出等式左边的那一项。在DDPM中，$q(\mathbf{x}_{t} | \mathbf{x}_{t - 1})$是一个定义好的式子，且$q(\mathbf{x}_{t} | \mathbf{x}_{t - 1}) = q(\mathbf{x}_{t} | \mathbf{x}_{t - 1}, \mathbf{x}_0)$。根据$q(\mathbf{x}_{t} | \mathbf{x}_{t - 1})$，可以推出$q(\mathbf{x}_{t} | \mathbf{x}_0)$。知道了$q(\mathbf{x}_{t} | \mathbf{x}_0)$，$q(\mathbf{x}_{t-1} | \mathbf{x}_0)$也就知道了（把公式里的$t$换成$t-1$就行了）。这样，在DDPM中，等式右边的式子全部已知，等式左边的$q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_{0})$可以直接求出来。</p>
<p>上述推理过程可以简单地表示为：知道$q(\mathbf{x}_{t} | \mathbf{x}_0)$和$q(\mathbf{x}_{t} | \mathbf{x}_{t - 1}, \mathbf{x}_0)$，就知道了神经网络的学习目标$q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0)$。这几个公式在DDPM中的具体形式如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
q(\mathbf{x}_{t} | \mathbf{x}_{t - 1}, \mathbf{x}_0) &=\mathcal{N}(\mathbf{x}_{t};\sqrt{1 - \beta_t}\mathbf{x}_{t - 1},\beta_t\mathbf{I}) \\
q(\mathbf{x}_{t} | \mathbf{x}_0)&=\mathcal{N}(\mathbf{x}_{t}; \sqrt{\bar{\alpha}_t}\mathbf{x}_{0}, (1-\bar{\alpha}_t)\mathbf{I}) \\
q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0) &= 
\mathcal{N}(\mathbf{x}_{t-1}; \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1 - \bar{\alpha}_{t}}\mathbf{x}_{t}+\frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1 - \bar{\alpha}_{t}}\mathbf{x}_{0}, \frac{1-\bar{\alpha}_{t-1}}{1 - \bar{\alpha}_{t}} \cdot \beta_t\mathbf{I})
\end{aligned}</script><p>其中，只有参数$\beta_t$是可调的。$\bar{\alpha}_t$是根据$\beta_t$算出的变量，其计算方法为：$\alpha_t=1-\beta_t, \bar{\alpha}_t=\prod_{i=1}^t\alpha_i$。</p>
<p>由于学习目标$q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0)$里只有一个未知变量$\mathbf{x}_0$，DDPM把学习目标简化成了只让神经网络根据$\mathbf{x}_{t}$拟合公式里的$\mathbf{x}_{0}$（更具体一点，是拟合从$\mathbf{x}_{0}$到$\mathbf{x}_{t}$的噪声）。也就是说，在训练时，$q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0)$的公式不会被用到，只有$\mathbf{x}_{t}$和$\mathbf{x}_{0}$两个量之间的公式$q(\mathbf{x}_{t} | \mathbf{x}_0)$会被用到。只有在采样时，$q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0)$的公式才会被用到。训练目标的推理过程可以总结为：</p>
<p><img src="/2023/07/07/20230702-DDIM/3.jpg" alt></p>
<blockquote>
<p>理解「DDPM的训练目标只有$\mathbf{x}_{0}$」对于理解DDIM非常关键。如果你在回顾DDPM时出现了问题，请再次阅读DDPM的相关介绍文章。</p>
</blockquote>
<h2 id="加速-DDPM"><a href="#加速-DDPM" class="headerlink" title="加速 DDPM"></a>加速 DDPM</h2><p>我们再次审视一下DDPM的推理过程：首先有$q(\mathbf{x}_{t} | \mathbf{x}_{t - 1}) = q(\mathbf{x}_{t} | \mathbf{x}_{t - 1}, \mathbf{x}_0)$。根据$q(\mathbf{x}_{t} | \mathbf{x}_{t - 1})$，可以推出$q(\mathbf{x}_{t} | \mathbf{x}_0)$。知道$q(\mathbf{x}_{t} | \mathbf{x}_0)$和$q(\mathbf{x}_{t} | \mathbf{x}_{t - 1}, \mathbf{x}_0)$，由贝叶斯公式，就知道了学习目标$q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0)$。</p>
<p>根据这一推理过程，DDIM论文的作者想到，假如我们把贝叶斯公式中的$t$替换成$t_2$, $t-1$替换成$t_1$，其中$t_2$是比$t_1$大的任意某一时刻，那么我们不就可以从$t_2$到$t_1$跳步骤去噪了吗？比如令$t_2 = t_1 + 10$，我们就可以求出去除10次噪声的公式，去噪的过程就快了10倍。</p>
<script type="math/tex; mode=display">
q(\mathbf{x}_{t_1} | \mathbf{x}_{t_2}, \mathbf{x}_0) = q(\mathbf{x}_{t_2} | \mathbf{x}_{t_1}, \mathbf{x}_0)\frac{q(\mathbf{x}_{t_1} | \mathbf{x}_0)}{q(\mathbf{x}_{t_2} | \mathbf{x}_0)}</script><p>修改之后，$q(\mathbf{x}_{t_1} | \mathbf{x}_0)$和$q(\mathbf{x}_{t_2} | \mathbf{x}_0)$依然很好求，只要把$t_1$, $t_2$代入普通的$q(\mathbf{x}_{t} | \mathbf{x}_0)$公式里就行。</p>
<script type="math/tex; mode=display">
q(\mathbf{x}_{t} | \mathbf{x}_0)=\mathcal{N}(\mathbf{x}_{t}; \sqrt{\bar{\alpha}_t}\mathbf{x}_{0}, (1-\bar{\alpha}_t)\mathbf{I})</script><p>但是，$q(\mathbf{x}_{t_2} | \mathbf{x}_{t_1}, \mathbf{x}_0)$怎么求呢？原来的$q(\mathbf{x}_{t} | \mathbf{x}_{t - 1}, \mathbf{x}_0)=\mathcal{N}(\mathbf{x}_{t};\sqrt{1 - \beta_t}\mathbf{x}_{t - 1},\beta_t\mathbf{I})$来自于DDPM的定义，我们能直接把公式拿来用。能不能把$q(\mathbf{x}_{t} | \mathbf{x}_{t - 1}, \mathbf{x}_0)$的公式稍微修改一下，让它兼容$q(\mathbf{x}_{t_2} | \mathbf{x}_{t_1}, \mathbf{x}_0)$呢？</p>
<p>修改$q(\mathbf{x}_{t} | \mathbf{x}_{t - 1}, \mathbf{x}_0)$的思路如下：假如我们能把公式中的$\beta_t$换成一个由$t$和$t-1$决定的变量，我们就能把$t$换成$t_2$，$t-1$换成$t_1$，也就得到了$q(\mathbf{x}_{t_2} | \mathbf{x}_{t_1}, \mathbf{x}_0)$。</p>
<p>那怎么修改$\beta_t$的形式呢？很简单。我们知道$\beta_t$决定了$\bar{\alpha}_t$：$\alpha_t=1-\beta_t, \bar{\alpha}_t=\prod_{i=1}^t\alpha_i$。那么我们用$\bar{\alpha}_t$除以$\bar{\alpha}_{t-1}$，不就得到了$1-\beta_t$了吗？也就是说：</p>
<script type="math/tex; mode=display">
\beta_t = 1-\frac{\bar{\alpha}_t}{\bar{\alpha}_{t-1}}.</script><p>我们把这个用$\bar{\alpha}_t$和$\bar{\alpha}_{t-1}$表示的$\beta_t$套入$q(\mathbf{x}_{t} | \mathbf{x}_{t - 1}, \mathbf{x}_0)$的公式里，再把$t$换成$t_2$，$t-1$换成$t_1$，就得到了$q(\mathbf{x}_{t_2} | \mathbf{x}_{t_1}, \mathbf{x}_0)$。有了这一项，贝叶斯公式等式右边那三项我们就全部已知，可以求出$q(\mathbf{x}_{t_1} | \mathbf{x}_{t_2}, \mathbf{x}_0)$，也就是可以一次性得到多个时刻后的去噪结果。</p>
<p>在这个过程中，我们只是把DDPM公式里的$\bar{\alpha}_t$换成$\bar{\alpha}_{t2}$，$\bar{\alpha}_{t-1}$换成$\bar{\alpha}_{t1}$，公式推导过程完全不变。网络的训练目标$\mathbf{x}_{0}$也没有发生改变，只是采样时的公式需要修改。这意味着我们可以先照着原DDPM的方法训练，再用这种更快速的方式采样。</p>
<p>我们之前只讨论了$t_1$到$t_2$为固定值的情况。实际上，我们不一定要间隔固定的时刻去噪一次，完全可以用原时刻序列的任意一个子序列来去噪。比如去噪100次的DDPM的去噪时刻序列为<code>[99, 98, ..., 0]</code>，我们可以随便取一个长度为10的子序列:<code>[99, 98, 77, 66, 55, 44, 33, 22, 1, 0]</code>，按这些时刻来去噪也能让采样速度加速10倍。但实践中没人会这样做，一般都是等间距地取时刻。</p>
<p>这样看来，在采样时，只有部分时刻才会被用到。那我们能不能顺着这个思路，干脆训练一个有效时刻更短（总时刻$T$不变）的DDPM，以加速训练呢？又或者保持有效训练时刻数不变，增大总时刻$T$呢？DDIM论文的作者提出了这些想法，认为这可以作为后续工作的研究方向。</p>
<h2 id="从-DDPM-到-DDIM"><a href="#从-DDPM-到-DDIM" class="headerlink" title="从 DDPM 到 DDIM"></a>从 DDPM 到 DDIM</h2><p>除了加速DDPM外，DDIM论文还提出了一种更普遍的DDPM。在这种新的数学模型下，我们可以任意调节采样时的方差大小。让我们来看一下这个数学模型的推导过程。</p>
<p>DDPM的学习目标$q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0)$由$q(\mathbf{x}_{t} | \mathbf{x}_0)$和$q(\mathbf{x}_{t} | \mathbf{x}_{t - 1}, \mathbf{x}_0)$决定。具体来说，在求解正态分布$q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0)$时，我们会将它的均值$\tilde{\mu}_t$和方差$\tilde{\beta}_t$设为未知量，并将条件$q(\mathbf{x}_{t} | \mathbf{x}_0)$、$q(\mathbf{x}_{t-1} | \mathbf{x}_0)$、$q(\mathbf{x}_{t} | \mathbf{x}_{t - 1}, \mathbf{x}_0)$代入，求解出确定的$\tilde{\mu}_t$和$\tilde{\beta}_t$。</p>
<p>在上文我们分析过，DDPM训练时只需要拟合$\mathbf{x}_0$，只需要用到$\mathbf{x}_0$和$\mathbf{x}_t$的关系$q(\mathbf{x}_{t} | \mathbf{x}_0)$。在不修改训练过程的前提下，我们能不能把限制$q(\mathbf{x}_{t} | \mathbf{x}_{t - 1}, \mathbf{x}_0)$去掉（即$q(\mathbf{x}_{t} | \mathbf{x}_{t - 1}, \mathbf{x}_0)$可以是任意一个正态分布，而不是我们提前定义好的一个正态分布），得到一个更普遍的DDPM呢？</p>
<p>这当然是可以的。根据基础的解方程知识，我们知道，去掉一个方程后，会多出一个自由变量。取消了$q(\mathbf{x}_{t} | \mathbf{x}_{t - 1}, \mathbf{x}_0)$的限制后，均值$\tilde{\mu}_t$和方差$\tilde{\beta}_t$就不能同时确定下来了。我们可以令方差$\tilde{\beta}_t$为自由变量，并让$\tilde{\mu}_t$用含$\tilde{\beta}_t$的式子表示出来。这样，我们就得到了一个方差可变的更一般的DDPM。</p>
<p>让我们来看一下这个新模型的具体公式。原来的DDPM的加噪声逆操作的分布为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0) = &
\mathcal{N}(\mathbf{x}_{t-1}; \\
&\frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1 - \bar{\alpha}_{t}}\mathbf{x}_{t}+\frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1 - \bar{\alpha}_{t}}\mathbf{x}_{0}, \\
&\frac{1-\bar{\alpha}_{t-1}}{1 - \bar{\alpha}_{t}} \cdot \beta_t\mathbf{I})
\end{aligned}</script><p>新的分布公式为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0) &= 
\mathcal{N}(\mathbf{x}_{t-1}; \\
&\sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_{0}+\sqrt{1-\bar{\alpha}_{t-1}-\tilde{\beta}_t} \cdot \frac{\mathbf{x}_{t}-\sqrt{\bar{\alpha}_t}\mathbf{x}_{0}}{\sqrt{1 - \bar{\alpha}_{t}}}, \\ 
&\tilde{\beta}_t\mathbf{I})
\end{aligned}</script><p>新公式是旧公式的一个推广版本。如果我们把DDPM的方差$(1-\bar{\alpha}_{t-1})/(1 - \bar{\alpha}_{t}) \cdot \beta_t$代入新公式里的$\tilde{\beta}_t$，就能把新公式还原成DDPM的公式。和DDPM的公式一样，我们也可以把$\mathbf{x}_{0}$拆成$\mathbf{x}_{t}$和噪声$\epsilon$表示的式子。</p>
<p>现在采样时方差可以随意取了，我们来讨论一种特殊的方差取值——$\tilde{\beta}_t=0$。也就是说，扩散模型的反向过程变成了一个没有噪声的确定性过程。给定随机噪声$\mathbf{x}_{T}$，我们只能得到唯一的采样结果$\mathbf{x}_{0}$。这种结果确定的概率模型被称为隐式概率模型（implicit probabilistic model）。所以，论文作者把方差为0的这种扩散模型称为DDIM（Denoising Diffusion Implicit Model）。</p>
<p>为了方便地选取方差值，作者将方差改写为</p>
<script type="math/tex; mode=display">
\tilde{\beta}_t(\eta)=\eta\frac{(1-\bar{\alpha}_{t-1})}{(1 - \bar{\alpha}_{t})} \cdot \beta_t</script><p>其中，$\eta\in[0, 1]$。通过选择不同的$\eta$，我们实际上是在DDPM和DDIM之间插值。$\eta$控制了插值的比例。$\eta=0$，模型是DDIM；$\eta=1$，模型是DDPM。</p>
<p>除此之外，DDPM论文曾在采样时使用了另一种方差取值：$\tilde{\beta}_t=\beta_t$，即去噪方差等于加噪方差。实验显示这个方差的采样结果还不错。我们可以把这个取值也用到DDIM论文提出的方法里，只不过这个方差值不能直接套进上面的公式。在代码实现部分我会介绍该怎么在DDIM方法中使用这个方差。</p>
<p>注意，在这一节的推导过程中，我们依然没有修改DDPM的训练目标。我们可以把这种的新的采样方法用在预训练的DDPM上。当然，我们可以在使用新的采样方法的同时也使用上一节的加速采样方法。</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>到这里为止，我们已经学完了DDIM论文的两大内容：加速采样、更换采样方差。加速采样的意义很好理解，它能大幅减少采样时间。可更换采样方差有什么意义呢？我们看完论文中的实验结果就知道了。</p>
<p>论文展示了新采样方法在不同方差、不同采样步数下的FID指标（越小越好）。其中，$\hat{\sigma}$表示使用DDPM中的$\tilde{\beta}_t=\beta_t$方差取值。实验结果非常有趣。在使用采样加速（步数比总时刻1000要小）时，$\eta=0$的DDIM的表现最好，而$\hat{\sigma}$的情况则非常差。而当$\eta$增大，模型越来越靠近DDPM时，用$\hat{\sigma}$的结果会越来越好。而在DDPM中，用$\hat{\sigma}$的结果是最好的。</p>
<p><img src="/2023/07/07/20230702-DDIM/4.jpg" alt></p>
<p>从这个实验结果中，我们可以得到一条很简单的实践指南：如果使用了采样加速，一定要用效果最好的DDIM；而使用原DDPM的话，可以维持原论文提出的$\tilde{\beta}_t=\beta_t$方差取值。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>DDIM论文提出了DDPM的两个拓展方向：加速采样、变更采样方差。通过同时使用这两个方法，我们能够在不重新训练DDPM、尽可能不降低生成质量的前提下，让扩散模型的采样速度大幅提升（一般可以快50倍）。让我们再从头理一理提出DDIM方法的思考过程。</p>
<p>为了能直接使用预训练的DDPM，我们希望在改进DDPM时不更改DDPM的训练过程。而经过简化后，DDPM的训练目标只有拟合$\mathbf{x}_{0}$，训练时只会用到前向过程公式$q(\mathbf{x}_{t} | \mathbf{x}_0)=\mathcal{N}(\mathbf{x}_{t}; \sqrt{\bar{\alpha}_t}\mathbf{x}_{0}, (1-\bar{\alpha}_t)\mathbf{I})$。所以，我们的改进应该建立在公式$q(\mathbf{x}_{t} | \mathbf{x}_0)$完全不变的前提下。</p>
<p>通过对DDPM反向过程公式的简单修改，也就是把$t$改成$t_2$，$t-1$改成$t_1$，我们可以把去噪一步的公式改成去噪多步的公式，以大幅加速DDPM。可是，这样改完之后，采样的质量会有明显的下降。</p>
<p>我们可以猜测，减少了采样迭代次数后，采样质量之所以下降，是因为每次估计的去噪均值更加不准确。而每次去噪迭代中的噪声（由方差项决定的那一项）放大了均值的不准确性。我们能不能干脆让去噪时的方差为0呢？为了让去噪时的方差可以自由变动，我们可以去掉DDPM的约束条件。由于贝叶斯公式里的$q(\mathbf{x}_{t} | \mathbf{x}_0)$不能修改，我们只能去掉$q(\mathbf{x}_{t} | \mathbf{x}_{t - 1}, \mathbf{x}_0)$的限制。去掉限制后，方差就成了自由变量。我们让去噪方差为0，让采样过程没有噪声。这样，就得到了本文提出的DDIM模型。实验证明，在采样迭代次数减少后，使用DDIM的生成结果是最优的。</p>
<p>在本文中，我较为严格地区分了DDPM和DDIM的叫法：DDPM指DDPM论文中提出的有1000个扩散时刻的模型，它的采样方差只有两种取值（$\tilde{\beta}_t=(1-\bar{\alpha}_{t-1})/(1 - \bar{\alpha}_{t}) \cdot \beta_t$, $\tilde{\beta}_t=\beta_t$）。DDIM指DDIM论文中提出的$\eta=0$的推广版DDPM模型。DDPM和DDIM都可以使用采样加速。但是，从习惯上我们会把没有优化加速的DDPM称为”DDPM”，把$\eta$可以任取，采样迭代次数可以任取的采样方法统称为”DDIM”。一些开源库中会有叫<code>DDIMSampler</code>的类，调节$\eta$的参数大概会命名为<code>eta</code>，调节迭代次数的参数大概会命名为<code>ddim_num_steps</code>。一般我们令<code>eta=0</code>，<code>ddim_num_steps=20</code>即可。</p>
<p>DDIM的代码实现没有太多的学习价值，只要在DDPM代码的基础上把新数学公式翻译成代码即可。其中唯一值得注意的就是如何在DDIM中使用DDPM的方差$\tilde{\beta}_t=\beta_t$。对此感兴趣的话可以阅读我接下来的代码实现介绍。</p>
<p>在这篇解读中，我略过了DDIM论文中的大部分数学推导细节。对DDIM数学模型的推导过程感兴趣的话，可以阅读我在参考文献中推荐的文章，或者看一看原论文。</p>
<h2 id="DDIM-PyTorch-实现"><a href="#DDIM-PyTorch-实现" class="headerlink" title="DDIM PyTorch 实现"></a>DDIM PyTorch 实现</h2><p>在这个项目中，我们将对一个在CelebAHQ上预训练的DDPM执行DDIM采样，尝试复现论文中的那个FID表格，以观察不同<code>eta</code>和<code>ddim_steps</code>对于采样结果的影响。</p>
<p>代码仓库：<a target="_blank" rel="noopener" href="https://github.com/SingleZombie/DL-Demos/tree/master/dldemos/ddim">https://github.com/SingleZombie/DL-Demos/tree/master/dldemos/ddim</a></p>
<h3 id="DDPM-基础项目"><a href="#DDPM-基础项目" class="headerlink" title="DDPM 基础项目"></a>DDPM 基础项目</h3><p>DDIM只是DDPM的一种采样改进策略。为了复现DDIM的结果，我们需要一个DDPM基础项目。由于DDPM并不是本文的重点，在这一小节里我将简要介绍我的DDPM实现代码的框架。</p>
<p>我们的实验需要使用CelebAHQ数据集，请在 <a target="_blank" rel="noopener" href="https://www.kaggle.com/datasets/badasstechie/celebahq-resized-256x256">https://www.kaggle.com/datasets/badasstechie/celebahq-resized-256x256</a> 下载该数据集并解压到项目的<code>data/celebA/celeba_hq_256</code>目录下。另外，我在Hugging Face上分享了一个在64x64 CelebAHQ上训练的DDPM模型：<a target="_blank" rel="noopener" href="https://huggingface.co/SingleZombie/dldemos/tree/main/ckpt/ddim">https://huggingface.co/SingleZombie/dldemos/tree/main/ckpt/ddim</a> ，请把它放到项目的<code>dldemos/ddim</code>目录下。</p>
<p>先运行<code>dldemos/ddim/dataset.py</code>下载MNIST，再直接运行<code>dldemos/ddim/main.py</code>，代码会自动完成MNIST上的训练，并执行步数1000的两种采样和步数20的三种采样，同时将结果保存在目录<code>work_dirs</code>中。以下是我得到的MNIST DDPM采样结果（存储在<code>work_dirs/diffusion_ddpm_sigma_hat.jpg</code>中）。</p>
<p><img src="/2023/07/07/20230702-DDIM/5.jpg" alt></p>
<p>为了查看64x64 CelebAHQ上的采样结果，可以在<code>dldemos/ddim/main.py</code>的main函数里把<code>config_id</code>改成<code>2</code>，再注释掉训练函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 0 for MNIST. See configs.py</span></span><br><span class="line">config_id = <span class="number">2</span></span><br><span class="line">cfg = configs[config_id]</span><br><span class="line">n_steps = <span class="number">1000</span></span><br><span class="line">device = <span class="string">&#x27;cuda&#x27;</span></span><br><span class="line">model_path = cfg[<span class="string">&#x27;model_path&#x27;</span>]</span><br><span class="line">img_shape = cfg[<span class="string">&#x27;img_shape&#x27;</span>]</span><br><span class="line">to_bgr = <span class="literal">False</span> <span class="keyword">if</span> cfg[<span class="string">&#x27;dataset_type&#x27;</span>] == <span class="string">&#x27;MNIST&#x27;</span> <span class="keyword">else</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">net = UNet(n_steps, img_shape, cfg[<span class="string">&#x27;channels&#x27;</span>], cfg[<span class="string">&#x27;pe_dim&#x27;</span>],</span><br><span class="line">           cfg.get(<span class="string">&#x27;with_attn&#x27;</span>, <span class="literal">False</span>), cfg.get(<span class="string">&#x27;norm_type&#x27;</span>, <span class="string">&#x27;ln&#x27;</span>))</span><br><span class="line">ddpm = DDPM(device, n_steps)</span><br><span class="line"></span><br><span class="line"><span class="comment"># train(ddpm,</span></span><br><span class="line"><span class="comment">#       net,</span></span><br><span class="line"><span class="comment">#       cfg[&#x27;dataset_type&#x27;],</span></span><br><span class="line"><span class="comment">#       resolution=(img_shape[1], img_shape[2]),</span></span><br><span class="line"><span class="comment">#       batch_size=cfg[&#x27;batch_size&#x27;],</span></span><br><span class="line"><span class="comment">#       n_epochs=cfg[&#x27;n_epochs&#x27;],</span></span><br><span class="line"><span class="comment">#       device=device,</span></span><br><span class="line"><span class="comment">#       ckpt_path=model_path)</span></span><br></pre></td></tr></table></figure>
<p>以下是我得到的CelebAHQ DDPM采样结果（存储在<code>work_dirs/diffusion_ddpm_sigma_hat.jpg</code>中）。</p>
<p><img src="/2023/07/07/20230702-DDIM/6.jpg" alt></p>
<p>项目目录下的<code>configs.py</code>存储了训练配置，<code>dataset.py</code>定义了<code>DataLoader</code>，<code>network.py</code>定义了U-Net的结构，<code>ddpm.py</code>和<code>ddim.py</code>分别定义了普通的DDPM前向过程和采样以及DDIM采样，<code>dist_train.py</code>提供了并行训练脚本，<code>dist_sample.py</code>提供了并行采样脚本，<code>main.py</code>提供了单卡运行的所有任务脚本。</p>
<p>在这个项目中，我们的主要的目标是基于其他文件，编写<code>ddim.py</code>。我们先来看一下原来的<code>DDPM</code>类是怎么实现的，再仿照它的接口写一个<code>DDIM</code>类。</p>
<h3 id="实现-DDIM-采样"><a href="#实现-DDIM-采样" class="headerlink" title="实现 DDIM 采样"></a>实现 DDIM 采样</h3><p>在我的设计中，<code>DDPM</code>类不是一个神经网络（<code>torch.nn.Module</code>），它仅仅维护了扩散模型的<code>alpha</code>等变量，并描述了前向过程和反向过程。</p>
<p>在<code>DDPM</code>类中，我们可以在初始化函数里定义好要用到的<code>self.betas, self.alphas, self.alpha_bars</code>变量。如果在工程项目中，我们可以预定义好更多的常量以节约采样时间。但在学习时，我们可以少写一点代码，让项目更清晰一点。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DDPM</span>():</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">                 device,</span></span></span><br><span class="line"><span class="params"><span class="function">                 n_steps: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 min_beta: <span class="built_in">float</span> = <span class="number">0.0001</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 max_beta: <span class="built_in">float</span> = <span class="number">0.02</span></span>):</span></span><br><span class="line">        betas = torch.linspace(min_beta, max_beta, n_steps).to(device)</span><br><span class="line">        alphas = <span class="number">1</span> - betas</span><br><span class="line">        alpha_bars = torch.empty_like(alphas)</span><br><span class="line">        product = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i, alpha <span class="keyword">in</span> <span class="built_in">enumerate</span>(alphas):</span><br><span class="line">            product *= alpha</span><br><span class="line">            alpha_bars[i] = product</span><br><span class="line">        self.betas = betas</span><br><span class="line">        self.n_steps = n_steps</span><br><span class="line">        self.alphas = alphas</span><br><span class="line">        self.alpha_bars = alpha_bars</span><br></pre></td></tr></table></figure>
<p>前向过程就是把正态分布的公式$q(\mathbf{x}_{t} | \mathbf{x}_0)=\mathcal{N}(\mathbf{x}_{t}; \sqrt{\bar{\alpha}_t}\mathbf{x}_{0}, (1-\bar{\alpha}_t)\mathbf{I})$翻译一下。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample_forward</span>(<span class="params">self, x, t, eps=<span class="literal">None</span></span>):</span></span><br><span class="line">    alpha_bar = self.alpha_bars[t].reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> eps <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        eps = torch.randn_like(x)</span><br><span class="line">    res = eps * torch.sqrt(<span class="number">1</span> - alpha_bar) + torch.sqrt(alpha_bar) * x</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p>在反向过程中，我们从<code>self.n_steps</code>到<code>1</code>枚举时刻<code>t</code>（代码中时刻和数组下标有1的偏差），按照公式算出每一步的去噪均值和方差，执行去噪。算法流程如下：</p>
<p><img src="/2023/07/07/20230702-DDIM/7.jpg" alt></p>
<p>参数<code>simple_var=True</code>表示令方差$\sigma_t^2=\beta_t$，而不是$(1-\bar{\alpha}_{t-1})/(1 - \bar{\alpha}_{t}) \cdot \beta_t$。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample_backward</span>(<span class="params">self, img_or_shape, net, device, simple_var=<span class="literal">True</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(img_or_shape, torch.Tensor):</span><br><span class="line">        x = img_or_shape</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        x = torch.randn(img_or_shape).to(device)</span><br><span class="line">    net = net.to(device)</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(self.n_steps - <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>), <span class="string">&quot;DDPM sampling&quot;</span>):</span><br><span class="line">        x = self.sample_backward_step(x, t, net, simple_var)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample_backward_step</span>(<span class="params">self, x_t, t, net, simple_var=<span class="literal">True</span></span>):</span></span><br><span class="line"></span><br><span class="line">    n = x_t.shape[<span class="number">0</span>]</span><br><span class="line">    t_tensor = torch.tensor([t] * n,</span><br><span class="line">                            dtype=torch.long).to(x_t.device).unsqueeze(<span class="number">1</span>)</span><br><span class="line">    eps = net(x_t, t_tensor)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> t == <span class="number">0</span>:</span><br><span class="line">        noise = <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> simple_var:</span><br><span class="line">            var = self.betas[t]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            var = (<span class="number">1</span> - self.alpha_bars[t - <span class="number">1</span>]) / (</span><br><span class="line">                <span class="number">1</span> - self.alpha_bars[t]) * self.betas[t]</span><br><span class="line">        noise = torch.randn_like(x_t)</span><br><span class="line">        noise *= torch.sqrt(var)</span><br><span class="line"></span><br><span class="line">    mean = (x_t -</span><br><span class="line">            (<span class="number">1</span> - self.alphas[t]) / torch.sqrt(<span class="number">1</span> - self.alpha_bars[t]) *</span><br><span class="line">            eps) / torch.sqrt(self.alphas[t])</span><br><span class="line">    x_t = mean + noise</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x_t</span><br></pre></td></tr></table></figure>
<p>接下来，我们来实现<code>DDIM</code>类。<code>DDIM</code>是<code>DDPM</code>的推广，我们可以直接用<code>DDIM</code>类继承<code>DDPM</code>类。它们共享初始化函数与前向过程函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DDIM</span>(<span class="params">DDPM</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">                 device,</span></span></span><br><span class="line"><span class="params"><span class="function">                 n_steps: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 min_beta: <span class="built_in">float</span> = <span class="number">0.0001</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 max_beta: <span class="built_in">float</span> = <span class="number">0.02</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(device, n_steps, min_beta, max_beta)</span><br></pre></td></tr></table></figure>
<p>我们要修改的只有反向过程的实现函数。整个函数的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample_backward</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">                    img_or_shape,</span></span></span><br><span class="line"><span class="params"><span class="function">                    net,</span></span></span><br><span class="line"><span class="params"><span class="function">                    device,</span></span></span><br><span class="line"><span class="params"><span class="function">                    simple_var=<span class="literal">True</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                    ddim_step=<span class="number">20</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                    eta=<span class="number">1</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> simple_var:</span><br><span class="line">        eta = <span class="number">1</span></span><br><span class="line">    ts = torch.linspace(self.n_steps, <span class="number">0</span>,</span><br><span class="line">                        (ddim_step + <span class="number">1</span>)).to(device).to(torch.long)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(img_or_shape, torch.Tensor):</span><br><span class="line">        x = img_or_shape</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        x = torch.randn(img_or_shape).to(device)</span><br><span class="line">    batch_size = x.shape[<span class="number">0</span>]</span><br><span class="line">    net = net.to(device)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(<span class="number">1</span>, ddim_step + <span class="number">1</span>),</span><br><span class="line">                  <span class="string">f&#x27;DDIM sampling with eta <span class="subst">&#123;eta&#125;</span> simple_var <span class="subst">&#123;simple_var&#125;</span>&#x27;</span>):</span><br><span class="line">        cur_t = ts[i - <span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">        prev_t = ts[i] - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        ab_cur = self.alpha_bars[cur_t]</span><br><span class="line">        ab_prev = self.alpha_bars[prev_t] <span class="keyword">if</span> prev_t &gt;= <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        t_tensor = torch.tensor([cur_t] * batch_size,</span><br><span class="line">                                dtype=torch.long).to(device).unsqueeze(<span class="number">1</span>)</span><br><span class="line">        eps = net(x, t_tensor)</span><br><span class="line">        var = eta * (<span class="number">1</span> - ab_prev) / (<span class="number">1</span> - ab_cur) * (<span class="number">1</span> - ab_cur / ab_prev)</span><br><span class="line">        noise = torch.randn_like(x)</span><br><span class="line"></span><br><span class="line">        first_term = (ab_prev / ab_cur)**<span class="number">0.5</span> * x</span><br><span class="line">        second_term = ((<span class="number">1</span> - ab_prev - var)**<span class="number">0.5</span> -</span><br><span class="line">                        (ab_prev * (<span class="number">1</span> - ab_cur) / ab_cur)**<span class="number">0.5</span>) * eps</span><br><span class="line">        <span class="keyword">if</span> simple_var:</span><br><span class="line">            third_term = (<span class="number">1</span> - ab_cur / ab_prev)**<span class="number">0.5</span> * noise</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            third_term = var**<span class="number">0.5</span> * noise</span><br><span class="line">        x = first_term + second_term + third_term</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>我们来把整个函数过一遍。先看一下函数的参数。相比DDPM，DDIM的采样会多出两个参数：<code>ddim_step, eta</code>。如正文所述，<code>ddim_step</code>表示执行几轮去噪迭代，<code>eta</code>表示DDPM和DDIM的插值系数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample_backward</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">                    img_or_shape,</span></span></span><br><span class="line"><span class="params"><span class="function">                    net,</span></span></span><br><span class="line"><span class="params"><span class="function">                    device,</span></span></span><br><span class="line"><span class="params"><span class="function">                    simple_var=<span class="literal">True</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                    ddim_step=<span class="number">20</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                    eta=<span class="number">1</span></span>):</span></span><br></pre></td></tr></table></figure>
<p>在开始迭代前，要做一些预处理。根据论文的描述，如果使用了DDPM的那种简单方差，一定要令<code>eta=1</code>。所以，一开始我们根据<code>simple_var</code>对<code>eta</code>做一个处理。之后，我们要准备好迭代时用到的时刻。整个迭代过程中，我们会用到从<code>self.n_steps</code>到<code>0</code>等间距的<code>ddim_step+1</code>个时刻（<code>self.n_steps</code>是初始时刻，不在去噪迭代中）。比如总时刻<code>self.n_steps=100</code>，<code>ddim_step=10</code>，<code>ts</code>数组里的内容就是<code>[100, 90, 80, 70, 60, 50, 40, 30, 20, 10, 0]</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> simple_var:</span><br><span class="line">    eta = <span class="number">1</span></span><br><span class="line">ts = torch.linspace(self.n_steps, <span class="number">0</span>,</span><br><span class="line">                    (ddim_step + <span class="number">1</span>)).to(device).to(torch.long)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">isinstance</span>(img_or_shape, torch.Tensor):</span><br><span class="line">    x = img_or_shape</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    x = torch.randn(img_or_shape).to(device)</span><br><span class="line">batch_size = x.shape[<span class="number">0</span>]</span><br><span class="line">net = net.to(device)</span><br></pre></td></tr></table></figure>
<p>做好预处理后，进入去噪循环。在for循环中，我们从<code>1</code>到<code>ddim_step</code>遍历<code>ts</code>的下标，从时刻数组<code>ts</code>里取出较大的时刻<code>cur_t</code>（正文中的$t_2$）和较小的时刻<code>prev_t</code>（正文中的$t_1$）。由于<code>self.alpha_bars</code>存储的是<code>t=1, t=2, ..., t=n_steps</code>时的变量，时刻和数组下标之间有一个1的偏移，我们要把<code>ts</code>里的时刻减去1得到时刻在<code>self.alpha_bars</code>里的下标，再取出对应的变量<code>ab_cur, ab_prev</code>。注意，在当前时刻为0时，<code>self.alpha_bars</code>是没有定义的。但由于<code>self.alpha_bars</code>表示连乘，我们可以特别地令当前时刻为0（<code>prev_t=-1</code>）时的<code>alpha_bar=1</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(<span class="number">1</span>, ddim_step + <span class="number">1</span>),</span><br><span class="line">              <span class="string">f&#x27;DDIM sampling with eta <span class="subst">&#123;eta&#125;</span> simple_var <span class="subst">&#123;simple_var&#125;</span>&#x27;</span>):</span><br><span class="line">    cur_t = ts[i - <span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">    prev_t = ts[i] - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    ab_cur = self.alpha_bars[cur_t]</span><br><span class="line">    ab_prev = self.alpha_bars[prev_t] <span class="keyword">if</span> prev_t &gt;= <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>准备好时刻后，我们使用和DDPM一样的方法，用U-Net估计生成<code>x_t</code>时的噪声<code>eps</code>，并准备好DDPM采样算法里的噪声<code>noise</code>（公式里的$\mathbf{z}$）。<br>与DDPM不同，在计算方差<code>var</code>时（公式里的$\sigma_t^2$），我们要给方差乘一个权重<code>eta</code>。<br><img src="/2023/07/07/20230702-DDIM/7.jpg" alt></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">t_tensor = torch.tensor([cur_t] * batch_size,</span><br><span class="line">                        dtype=torch.long).to(device).unsqueeze(<span class="number">1</span>)</span><br><span class="line">eps = net(x, t_tensor)</span><br><span class="line">var = eta * (<span class="number">1</span> - ab_prev) / (<span class="number">1</span> - ab_cur) * (<span class="number">1</span> - ab_cur / ab_prev)</span><br><span class="line">noise = torch.randn_like(x)</span><br></pre></td></tr></table></figure>
<p>接下来，我们要把之前算好的所有变量用起来，套入DDIM的去噪均值计算公式中。</p>
<script type="math/tex; mode=display">
\begin{aligned}
q(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_0) &= 
\mathcal{N}(\mathbf{x}_{t-1}; \\
&\sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_{0}+\sqrt{1-\bar{\alpha}_{t-1}-\tilde{\beta}_t} \cdot \frac{\mathbf{x}_{t}-\sqrt{\bar{\alpha}_t}\mathbf{x}_{0}}{\sqrt{1 - \bar{\alpha}_{t}}}, \\ 
&\tilde{\beta}_t\mathbf{I})
\end{aligned}</script><p>也就是(设$\sigma_t^2 = \tilde{\beta}_t$, $\mathbf{z}$为来自标准正态分布的噪声)：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{x}_{t-1} =& \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_{0}+\sqrt{1-\bar{\alpha}_{t-1}-\sigma_t^2} \cdot \frac{\mathbf{x}_{t}-\sqrt{\bar{\alpha}_t}\mathbf{x}_{0}}{\sqrt{1 - \bar{\alpha}_{t}}} + \\
&\sigma_t\mathbf{z}
\end{aligned}</script><p>由于我们只有噪声$\epsilon$，要把$\mathbf{x}_0=(\mathbf{x}_t-\sqrt{1-\bar{\alpha}_t}\epsilon)/\sqrt{\bar{\alpha}_t}$代入，得到不含$\mathbf{x}_0$的公式：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{x}_{t-1} =& \sqrt{\frac{\bar{\alpha}_{t-1}}{\bar{\alpha}_{t}}} \mathbf{x}_{t}+ \\
&(\sqrt{1-{\bar{\alpha}}_{t-1}-\sigma_t^2} - \sqrt{\frac{\bar{\alpha}_{t-1}(1-\bar{\alpha}_t)}{\bar{\alpha}_t}})\epsilon+\\
&\sigma_t\mathbf{z}
\end{aligned}</script><p>我在代码里把公式的三项分别命名为<code>first_term, second_term, third_term</code>，以便查看。</p>
<p>特别地，当使用DDPM的$\hat{\sigma_t}$方差取值（令$\sigma_t^2=\beta_t=\hat{\sigma_t}^2$）时，不能把这个方差套入公式中，不然$\sqrt{1-{\bar{\alpha}}_{t}-\sigma_t^2}$的根号里的数会小于0。DDIM论文提出的做法是，只修改后面和噪声$\mathbf{z}$有关的方差项，前面这个根号里的方差项保持$\sigma_t^2=(1-\bar{\alpha}_{t-1})/(1 - \bar{\alpha}_{t}) \cdot \beta_t$ ($\eta=1$)的取值。</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{x}_{t-1} =& \sqrt{\frac{\bar{\alpha}_{t-1}}{\bar{\alpha}_{t}}} \mathbf{x}_{t}+ \\
&(\sqrt{1-{\bar{\alpha}}_{t-1}-\frac{1-\bar{\alpha}_{t-1}}{1 - \bar{\alpha}_{t}}\beta_t} - \sqrt{\frac{\bar{\alpha}_{t-1}(1-\bar{\alpha}_t)}{\bar{\alpha}_t}})\epsilon+\\
&\hat{\sigma_t}\mathbf{z}
\end{aligned}</script><p>当然，上面这些公式全都是在描述$t$到$t-1$。当描述$t_2$到$t_1$时，只需要把$\beta_t$换成$1-\frac{\bar{\alpha}_t}{\bar{\alpha}_{t-1}}$，再把所有$t$换成$t_2$，$t-1$换成$t_1$即可。</p>
<p>把上面的公式和处理逻辑翻译成代码，就是这样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">first_term = (ab_prev / ab_cur)**<span class="number">0.5</span> * x</span><br><span class="line">second_term = ((<span class="number">1</span> - ab_prev - var)**<span class="number">0.5</span> -</span><br><span class="line">                (ab_prev * (<span class="number">1</span> - ab_cur) / ab_cur)**<span class="number">0.5</span>) * eps</span><br><span class="line"><span class="keyword">if</span> simple_var:</span><br><span class="line">    third_term = (<span class="number">1</span> - ab_cur / ab_prev)**<span class="number">0.5</span> * noise</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    third_term = var**<span class="number">0.5</span> * noise</span><br><span class="line">x = first_term + second_term + third_term</span><br></pre></td></tr></table></figure>
<p>这样，下一刻的<code>x</code>就算完了。反复执行循环即可得到最终的结果。</p>
<h3 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h3><p>写完了DDIM采样后，我们可以编写一个随机生成图片的函数。由于<code>DDPM</code>和<code>DDIM</code>的接口非常相似，我们可以用同一套代码实现DDPM或DDIM的采样。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample_imgs</span>(<span class="params">ddpm,</span></span></span><br><span class="line"><span class="params"><span class="function">                net,</span></span></span><br><span class="line"><span class="params"><span class="function">                output_path,</span></span></span><br><span class="line"><span class="params"><span class="function">                img_shape,</span></span></span><br><span class="line"><span class="params"><span class="function">                n_sample=<span class="number">64</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                device=<span class="string">&#x27;cuda&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                simple_var=<span class="literal">True</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                to_bgr=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                **kwargs</span>):</span></span><br><span class="line">    <span class="keyword">if</span> img_shape[<span class="number">1</span>] &gt;= <span class="number">256</span>:</span><br><span class="line">        max_batch_size = <span class="number">16</span></span><br><span class="line">    <span class="keyword">elif</span> img_shape[<span class="number">1</span>] &gt;= <span class="number">128</span>:</span><br><span class="line">        max_batch_size = <span class="number">64</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        max_batch_size = <span class="number">256</span></span><br><span class="line"></span><br><span class="line">    net = net.to(device)</span><br><span class="line">    net = net.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">while</span> n_sample &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> n_sample &gt;= max_batch_size:</span><br><span class="line">                batch_size = max_batch_size</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                batch_size = n_sample</span><br><span class="line">            n_sample -= batch_size</span><br><span class="line">            shape = (batch_size, *img_shape)</span><br><span class="line">            imgs = ddpm.sample_backward(shape,</span><br><span class="line">                                        net,</span><br><span class="line">                                        device=device,</span><br><span class="line">                                        simple_var=simple_var,</span><br><span class="line">                                        **kwargs).detach().cpu()</span><br><span class="line">            imgs = (imgs + <span class="number">1</span>) / <span class="number">2</span> * <span class="number">255</span></span><br><span class="line">            imgs = imgs.clamp(<span class="number">0</span>, <span class="number">255</span>).to(torch.uint8)</span><br><span class="line"></span><br><span class="line">            img_list = einops.rearrange(imgs, <span class="string">&#x27;n c h w -&gt; n h w c&#x27;</span>).numpy()</span><br><span class="line">            output_dir = os.path.splitext(output_path)[<span class="number">0</span>]</span><br><span class="line">            os.makedirs(output_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">            <span class="keyword">for</span> i, img <span class="keyword">in</span> <span class="built_in">enumerate</span>(img_list):</span><br><span class="line">                <span class="keyword">if</span> to_bgr:</span><br><span class="line">                    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)</span><br><span class="line">                cv2.imwrite(<span class="string">f&#x27;<span class="subst">&#123;output_dir&#125;</span>/<span class="subst">&#123;i+index&#125;</span>.jpg&#x27;</span>, img)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># First iteration</span></span><br><span class="line">            <span class="keyword">if</span> index == <span class="number">0</span>:</span><br><span class="line">                imgs = einops.rearrange(imgs,</span><br><span class="line">                                        <span class="string">&#x27;(b1 b2) c h w -&gt; (b1 h) (b2 w) c&#x27;</span>,</span><br><span class="line">                                        b1=<span class="built_in">int</span>(batch_size**<span class="number">0.5</span>))</span><br><span class="line">                imgs = imgs.numpy()</span><br><span class="line">                <span class="keyword">if</span> to_bgr:</span><br><span class="line">                    imgs = cv2.cvtColor(imgs, cv2.COLOR_RGB2BGR)</span><br><span class="line">                cv2.imwrite(output_path, imgs)</span><br><span class="line"></span><br><span class="line">            index += batch_size</span><br></pre></td></tr></table></figure>
<p>为了生成大量图片以计算FID，在这个函数中我加入了很多和batch有关的处理。剔除这些处理代码以及图像存储后处理代码，和采样有关的核心代码为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample_imgs</span>(<span class="params">ddpm,</span></span></span><br><span class="line"><span class="params"><span class="function">                net,</span></span></span><br><span class="line"><span class="params"><span class="function">                output_path,</span></span></span><br><span class="line"><span class="params"><span class="function">                img_shape,</span></span></span><br><span class="line"><span class="params"><span class="function">                n_sample=<span class="number">64</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                device=<span class="string">&#x27;cuda&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                simple_var=<span class="literal">True</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                to_bgr=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                **kwargs</span>):</span></span><br><span class="line"></span><br><span class="line">    net = net.to(device)</span><br><span class="line">    net = net.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        shape = (n_sample, *img_shape)</span><br><span class="line">        imgs = ddpm.sample_backward(shape,</span><br><span class="line">                                    net,</span><br><span class="line">                                    device=device,</span><br><span class="line">                                    simple_var=simple_var,</span><br><span class="line">                                    **kwargs).detach().cpu()</span><br></pre></td></tr></table></figure>
<p>如果是用DDPM采样，把参数表里的那些参数填完就行了；如果是DDIM采样，则需要在<code>kwargs</code>里指定<code>ddim_step</code>和<code>eta</code>。</p>
<p>使用这个函数，我们可以进行不同<code>ddim_step</code>和不同<code>eta</code>下的64x64 CelebAHQ采样实验，以尝试复现DDIM论文的实验结果。</p>
<p><img src="/2023/07/07/20230702-DDIM/4.jpg" alt></p>
<p>我们先准备好变量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">net = UNet(n_steps, img_shape, cfg[<span class="string">&#x27;channels&#x27;</span>], cfg[<span class="string">&#x27;pe_dim&#x27;</span>],</span><br><span class="line">            cfg.get(<span class="string">&#x27;with_attn&#x27;</span>, <span class="literal">False</span>), cfg.get(<span class="string">&#x27;norm_type&#x27;</span>, <span class="string">&#x27;ln&#x27;</span>))</span><br><span class="line">ddpm = DDPM(device, n_steps)</span><br><span class="line">ddim = DDIM(device, n_steps)</span><br><span class="line">net.load_state_dict(torch.load(model_path))</span><br></pre></td></tr></table></figure>
<p>第一组实验是总时刻保持1000，使用$\hat{\sigma}_t$（标准DDPM）和$\eta=0$（标准DDIM）的实验。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">sample_imgs(ddpm,</span><br><span class="line">            net,</span><br><span class="line">            <span class="string">&#x27;work_dirs/diffusion_ddpm_sigma_hat.jpg&#x27;</span>,</span><br><span class="line">            img_shape,</span><br><span class="line">            device=device,</span><br><span class="line">            to_bgr=to_bgr)</span><br><span class="line">sample_imgs(ddim,</span><br><span class="line">            net,</span><br><span class="line">            <span class="string">&#x27;work_dirs/diffusion_ddpm_eta_0.jpg&#x27;</span>,</span><br><span class="line">            img_shape,</span><br><span class="line">            device=device,</span><br><span class="line">            to_bgr=to_bgr,</span><br><span class="line">            ddim_step=<span class="number">1000</span>,</span><br><span class="line">            simple_var=<span class="literal">False</span>,</span><br><span class="line">            eta=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>把参数<code>n_samples</code>改成<code>30000</code>，就可以生成30000张图像，以和30000张图像的CelebAHQ之间算FID指标。由于总时刻1000的采样速度非常非常慢，建议使用<code>dist_sample.py</code>并行采样。</p>
<p>算FID指标时，可以使用torch fidelity库。使用pip即可安装此库。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch-fidelity</span><br></pre></td></tr></table></figure>
<p>之后就可以使用命令<code>fidelity</code>来算指标了。假设我们把降采样过的CelebAHQ存储在<code>data/celebA/celeba_hq_64</code>，把我们生成的30000张图片存在<code>work_dirs/diffusion_ddpm_sigma_hat</code>，就可以用下面的命令算FID指标。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fidelity --gpu <span class="number">0</span> --fid --input1 work_dirs/diffusion_ddpm_sigma_hat --input2 data/celebA/celeba_hq_64</span><br></pre></td></tr></table></figure>
<p>整体来看，我的模型比论文差一点，总的FID会高一点。各个配置下的对比结果也稍有出入。在第一组实验中，使用$\hat{\sigma}_t$时，我的FID是13.68；使用$\eta=0$时，我的FID是13.09。而论文中用$\hat{\sigma}_t$时的FID比$\eta=0$时更低。</p>
<p>我们还可以做第二组实验，测试<code>ddim_step=20</code>（我设置的默认步数）时使用$\eta=0$, $\eta=1$, $\hat{\sigma}_t$的生成效果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">sample_imgs(ddim,</span><br><span class="line">            net,</span><br><span class="line">            <span class="string">&#x27;work_dirs/diffusion_ddim_sigma_hat.jpg&#x27;</span>,</span><br><span class="line">            img_shape,</span><br><span class="line">            device=device,</span><br><span class="line">            simple_var=<span class="literal">True</span>,</span><br><span class="line">            to_bgr=to_bgr)</span><br><span class="line">sample_imgs(ddim,</span><br><span class="line">            net,</span><br><span class="line">            <span class="string">&#x27;work_dirs/diffusion_ddim_eta_1.jpg&#x27;</span>,</span><br><span class="line">            img_shape,</span><br><span class="line">            device=device,</span><br><span class="line">            simple_var=<span class="literal">False</span>,</span><br><span class="line">            eta=<span class="number">1</span>,</span><br><span class="line">            to_bgr=to_bgr)</span><br><span class="line">sample_imgs(ddim,</span><br><span class="line">            net,</span><br><span class="line">            <span class="string">&#x27;work_dirs/diffusion_ddim_eta_0.jpg&#x27;</span>,</span><br><span class="line">            img_shape,</span><br><span class="line">            device=device,</span><br><span class="line">            simple_var=<span class="literal">False</span>,</span><br><span class="line">            eta=<span class="number">0</span>,</span><br><span class="line">            to_bgr=to_bgr)</span><br></pre></td></tr></table></figure>
<p>我的FID结果是：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">eta=0: 17.80</span><br><span class="line">eta=1: 24.00</span><br><span class="line">sigma hat: 213.16</span><br></pre></td></tr></table></figure><br>这里得到的实验结果和论文一致。减少采样迭代次数后，生成质量略有降低。同采样步数下，<code>eta=0</code>最优。使用<code>sigma hat</code>的结果会有非常多的噪声，差得完全不能看。</p>
<p>综合上面两个实验来看，不管什么情况下，使用<code>eta=0</code>，得到的结果都不会太差。</p>
<p>从生成速度上来看，在64x64 CelebAHQ上生成256张图片，<code>ddim_step=20</code>时只要3秒不到，而<code>ddim_step=1000</code>时要200秒。基本上是步数减少到几分之一就提速几倍。可见，DDIM加速采样对于扩散模型来说是必要的。</p>
<h2 id="参考文献及学习提示"><a href="#参考文献及学习提示" class="headerlink" title="参考文献及学习提示"></a>参考文献及学习提示</h2><p>如果对DDIM公式推导及其他数学知识感兴趣，欢迎阅读苏剑林的文章：<br><a target="_blank" rel="noopener" href="https://spaces.ac.cn/archives/9181。">https://spaces.ac.cn/archives/9181。</a></p>
<p>DDIM的论文为Denoising diffusion implicit models(<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2010.02502)。">https://arxiv.org/abs/2010.02502)。</a></p>
<p>我在本文使用的公式符号都基于DDPM论文，与上面两篇文章使用的符号不一样。比如DDIM论文里的$\alpha$在本文中是用$\bar{\alpha}$表示。</p>
<p>DDIM论文在介绍新均值公式时很不友好地在3.1节直接不加解释地给出了公式的形式，并在附录B中以先给结论再证明这种和逻辑思维完全反过来的方法介绍了公式的由来。建议去阅读苏剑林的文章，看看是怎么按正常的思考方式正向推导出DDIM公式。</p>
<p>除了在3.1节直接甩给你一个公式外，DDIM论文后面的地方都很好读懂。DDIM后面还介绍了一些比较有趣的内容，比如4.3节介绍了扩散模型和常微分方程的关系，它可以帮助我们理解为什么DDPM会设置$T=1000$这么长的加噪步数。5.3节中作者介绍了如何用DDIM在两幅图像间插值。</p>
<p>要回顾DDPM的知识，欢迎阅读我之前的文章：DDPM详解。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a>
              <a href="/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/" rel="tag"># 扩散模型</a>
              <a href="/tags/Python/" rel="tag"># Python</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/07/07/20230330-diffusion-model/" rel="prev" title="扩散模型(Diffusion Model)详解：直观理解、数学原理、PyTorch 实现">
      <i class="fa fa-chevron-left"></i> 扩散模型(Diffusion Model)详解：直观理解、数学原理、PyTorch 实现
    </a></div>
      <div class="post-nav-item">
    <a href="/2024/01/23/20230707-SD1/" rel="next" title="Stable Diffusion 解读（一）：回顾早期工作">
      Stable Diffusion 解读（一）：回顾早期工作 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%9E%E9%A1%BE-DDPM"><span class="nav-number">1.</span> <span class="nav-text">回顾 DDPM</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8A%A0%E9%80%9F-DDPM"><span class="nav-number">2.</span> <span class="nav-text">加速 DDPM</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%8E-DDPM-%E5%88%B0-DDIM"><span class="nav-number">3.</span> <span class="nav-text">从 DDPM 到 DDIM</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C"><span class="nav-number">4.</span> <span class="nav-text">实验</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">5.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DDIM-PyTorch-%E5%AE%9E%E7%8E%B0"><span class="nav-number">6.</span> <span class="nav-text">DDIM PyTorch 实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#DDPM-%E5%9F%BA%E7%A1%80%E9%A1%B9%E7%9B%AE"><span class="nav-number">6.1.</span> <span class="nav-text">DDPM 基础项目</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0-DDIM-%E9%87%87%E6%A0%B7"><span class="nav-number">6.2.</span> <span class="nav-text">实现 DDIM 采样</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C-1"><span class="nav-number">6.3.</span> <span class="nav-text">实验</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE%E5%8F%8A%E5%AD%A6%E4%B9%A0%E6%8F%90%E7%A4%BA"><span class="nav-number">7.</span> <span class="nav-text">参考文献及学习提示</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Zhou Yifan</p>
  <div class="site-description" itemprop="description">A foresighted strategist with big-picture thinking. 大局观选手。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">130</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">57</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhou Yifan</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
